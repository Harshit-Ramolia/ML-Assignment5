{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWUL0AyLVICl"
      },
      "source": [
        "# VGG-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4YxSprwdUn9_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 140 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:19:02.437201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - ETA: 0s - loss: 1.0209 - accuracy: 0.5143"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:19:09.640213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 9s 3s/step - loss: 1.0209 - accuracy: 0.5143 - val_loss: 0.7386 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.9466 - accuracy: 0.4714 - val_loss: 0.6714 - val_accuracy: 0.5333\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.7636 - accuracy: 0.5786 - val_loss: 0.6446 - val_accuracy: 0.7167\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.7468 - accuracy: 0.5571 - val_loss: 0.9556 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.6259 - accuracy: 0.6214 - val_loss: 0.6891 - val_accuracy: 0.5167\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.6664 - accuracy: 0.6357 - val_loss: 0.5766 - val_accuracy: 0.6167\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.5277 - accuracy: 0.7000 - val_loss: 0.5524 - val_accuracy: 0.7833\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.4655 - accuracy: 0.7857 - val_loss: 0.5493 - val_accuracy: 0.7167\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.4447 - accuracy: 0.8286 - val_loss: 0.5096 - val_accuracy: 0.8167\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.4018 - accuracy: 0.8571 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.3679 - accuracy: 0.9071 - val_loss: 0.4893 - val_accuracy: 0.8667\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.3331 - accuracy: 0.9143 - val_loss: 0.5503 - val_accuracy: 0.6667\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.3430 - accuracy: 0.8714 - val_loss: 0.4858 - val_accuracy: 0.8667\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.3112 - accuracy: 0.9143 - val_loss: 0.4790 - val_accuracy: 0.7833\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.2759 - accuracy: 0.9286 - val_loss: 0.4587 - val_accuracy: 0.8667\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2412 - accuracy: 0.9429 - val_loss: 0.4787 - val_accuracy: 0.7833\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2339 - accuracy: 0.9500 - val_loss: 0.4529 - val_accuracy: 0.8500\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2569 - accuracy: 0.8786 - val_loss: 0.4761 - val_accuracy: 0.7833\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.2202 - accuracy: 0.9500 - val_loss: 0.4467 - val_accuracy: 0.8500\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.1827 - accuracy: 0.9643 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 6s 3s/step - loss: 0.1505 - accuracy: 0.9714 - val_loss: 0.4629 - val_accuracy: 0.8000\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1509 - accuracy: 0.9786 - val_loss: 0.4610 - val_accuracy: 0.8167\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.1318 - accuracy: 0.9857 - val_loss: 0.4429 - val_accuracy: 0.8167\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.1342 - accuracy: 0.9714 - val_loss: 0.4673 - val_accuracy: 0.8167\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.1119 - accuracy: 0.9929 - val_loss: 0.4534 - val_accuracy: 0.8167\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.1006 - accuracy: 0.9929 - val_loss: 0.4545 - val_accuracy: 0.8167\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0995 - accuracy: 0.9929 - val_loss: 0.4777 - val_accuracy: 0.8167\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0910 - accuracy: 0.9929 - val_loss: 0.4591 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0816 - accuracy: 0.9929 - val_loss: 0.4643 - val_accuracy: 0.8167\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0724 - accuracy: 0.9929 - val_loss: 0.4783 - val_accuracy: 0.7833\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0781 - accuracy: 0.9929 - val_loss: 0.4786 - val_accuracy: 0.8167\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0626 - accuracy: 0.9929 - val_loss: 0.4730 - val_accuracy: 0.7833\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0632 - accuracy: 0.9929 - val_loss: 0.4707 - val_accuracy: 0.8000\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0524 - accuracy: 0.9929 - val_loss: 0.4822 - val_accuracy: 0.8167\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.7833\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0530 - accuracy: 0.9929 - val_loss: 0.5205 - val_accuracy: 0.8167\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.7833\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0440 - accuracy: 0.9929 - val_loss: 0.5581 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.7833\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0452 - accuracy: 0.9929 - val_loss: 0.4808 - val_accuracy: 0.7833\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8167\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.8167\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.8167\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.7833\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8167\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.8167\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.7667\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.8000\n",
            "No. of Parameters:  40961153\n",
            "Time:  319.0751459598541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:24:20.882037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.5110 - accuracy: 0.8000\n",
            "Test : > 80.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:24:23.821655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 834ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Train : > 100.000\n",
            "2/2 [==============================] - 0s 95ms/step\n"
          ]
        }
      ],
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import expand_dims as tf_expand_dims\n",
        "from tensorflow import summary\n",
        "from keras import backend as K\n",
        "from keras import callbacks\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time\n",
        "import os\n",
        "import io\n",
        "from datetime import datetime\n",
        "\n",
        "logs_folder = \"logs_vgg1\"\n",
        "if os.path.exists(logs_folder):\n",
        "    os.system(f\"rm -rf {logs_folder}\")\n",
        "\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "    # Save the plot to a PNG in memory.\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    # Convert PNG buffer to TF image\n",
        "    image = tf_image.decode_png(buf.getvalue(), channels=4)\n",
        "    # Add the batch dimension\n",
        "    image = tf_expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(images, label_arr, pred_arr):\n",
        "    \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "    # Create a figure to contain the plot.\n",
        "    figure = plt.figure(figsize=(50, 50))\n",
        "    for i in range(30):\n",
        "        # Start next subplot.\n",
        "        plt.subplot(\n",
        "            8, 5, i + 1, title=f'Actual :+{label_arr[i]}+| Pred : {pred_arr[i]}')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "    return figure\n",
        "\n",
        "# define cnn model\n",
        "\n",
        "\n",
        "def vgg_one():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "\n",
        "\n",
        "def run_test_harness():\n",
        "\n",
        "    logdir = \"logs_vgg1/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
        "    model = vgg_one()\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "    train_it = datagen.flow_from_directory('dataset_harp_vs_violin/train/',\n",
        "                                           class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    test_it = datagen.flow_from_directory('dataset_harp_vs_violin/test/',\n",
        "                                          class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    start = time.time()\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "                                  validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=1, callbacks=[tensorboard_callback],)\n",
        "    end = time.time()\n",
        "\n",
        "    print('No. of Parameters: ', model.count_params())\n",
        "\n",
        "    print(\"Time: \", end - start)\n",
        "\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n",
        "    print('Test : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    _, acc = model.evaluate_generator(train_it, steps=len(train_it), verbose=1)\n",
        "    print('Train : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    summarize_diagnostics(history)\n",
        "\n",
        "    label_dict = {}\n",
        "    for key, value in test_it.class_indices.items():\n",
        "        label_dict[value] = key\n",
        "\n",
        "    x, y = test_it.next()\n",
        "    images = x\n",
        "    labels = y\n",
        "    predictions = model.predict(images)\n",
        "    # print(x.shape,y.shape)\n",
        "    label_vals = []\n",
        "    pred_vals = []\n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        pred = round(predictions[j][0])\n",
        "        # print(k, label_dict[int(label)], label_dict[pred])\n",
        "        label_vals.append(label_dict[int(label)])\n",
        "        pred_vals.append(label_dict[pred])\n",
        "        # k += 1\n",
        "\n",
        "    figure = image_grid(images, label_vals, pred_vals)\n",
        "    file_writer = summary.create_file_writer(logdir)\n",
        "    with file_writer.as_default():\n",
        "        summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Uq3xAbVPug"
      },
      "source": [
        "# VGG-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EN3ZlfEAU7QX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 140 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:24:43.982604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.5929"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:24:51.501024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 9s 4s/step - loss: 0.6777 - accuracy: 0.5929 - val_loss: 2.0743 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 3.7703 - accuracy: 0.4714 - val_loss: 0.9525 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 1.1734 - accuracy: 0.5000 - val_loss: 1.0959 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.8645 - accuracy: 0.5357 - val_loss: 0.8128 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.7957 - accuracy: 0.5000 - val_loss: 0.7580 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.7024 - accuracy: 0.5000 - val_loss: 0.7000 - val_accuracy: 0.4667\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.6837 - accuracy: 0.5786 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6872 - accuracy: 0.5071 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.6842 - accuracy: 0.5286 - val_loss: 0.6897 - val_accuracy: 0.5167\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.6784 - accuracy: 0.5929 - val_loss: 0.6860 - val_accuracy: 0.5667\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6714 - accuracy: 0.6714 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.6614 - accuracy: 0.6786 - val_loss: 0.6837 - val_accuracy: 0.5333\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.6506 - accuracy: 0.6643 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6325 - accuracy: 0.7786 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.6130 - accuracy: 0.8286 - val_loss: 0.6546 - val_accuracy: 0.7000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.5894 - accuracy: 0.7929 - val_loss: 0.6462 - val_accuracy: 0.6167\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.5686 - accuracy: 0.8429 - val_loss: 0.6364 - val_accuracy: 0.6333\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 8s 4s/step - loss: 0.5458 - accuracy: 0.8571 - val_loss: 0.6211 - val_accuracy: 0.7167\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.5235 - accuracy: 0.8786 - val_loss: 0.6114 - val_accuracy: 0.6833\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.5173 - accuracy: 0.8357 - val_loss: 0.5990 - val_accuracy: 0.7167\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.4975 - accuracy: 0.8429 - val_loss: 0.6261 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.4756 - accuracy: 0.8429 - val_loss: 0.5718 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.4336 - accuracy: 0.8929 - val_loss: 0.5818 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3998 - accuracy: 0.9071 - val_loss: 0.5780 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3994 - accuracy: 0.8643 - val_loss: 0.5432 - val_accuracy: 0.8167\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3542 - accuracy: 0.9286 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3511 - accuracy: 0.9000 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3216 - accuracy: 0.9000 - val_loss: 0.5344 - val_accuracy: 0.7000\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.2902 - accuracy: 0.9500 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3286 - accuracy: 0.8857 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3103 - accuracy: 0.9071 - val_loss: 0.6951 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 8s 4s/step - loss: 0.3044 - accuracy: 0.8714 - val_loss: 0.5168 - val_accuracy: 0.7833\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.2947 - accuracy: 0.9000 - val_loss: 0.6063 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.2329 - accuracy: 0.9429 - val_loss: 0.5655 - val_accuracy: 0.7000\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.2380 - accuracy: 0.9071 - val_loss: 0.5622 - val_accuracy: 0.7333\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.2167 - accuracy: 0.9643 - val_loss: 0.5990 - val_accuracy: 0.6833\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.2326 - accuracy: 0.9286 - val_loss: 0.5352 - val_accuracy: 0.7667\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.1738 - accuracy: 0.9643 - val_loss: 0.6123 - val_accuracy: 0.7000\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1803 - accuracy: 0.9286 - val_loss: 0.5202 - val_accuracy: 0.8000\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1466 - accuracy: 0.9857 - val_loss: 0.5210 - val_accuracy: 0.7833\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1377 - accuracy: 0.9929 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.1272 - accuracy: 0.9857 - val_loss: 0.5201 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.1289 - accuracy: 0.9786 - val_loss: 0.5225 - val_accuracy: 0.8000\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.1206 - accuracy: 0.9857 - val_loss: 0.5277 - val_accuracy: 0.7833\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1076 - accuracy: 0.9857 - val_loss: 0.5238 - val_accuracy: 0.8000\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.0968 - accuracy: 0.9929 - val_loss: 0.5172 - val_accuracy: 0.8000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.0944 - accuracy: 0.9857 - val_loss: 0.5280 - val_accuracy: 0.7667\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.0851 - accuracy: 0.9929 - val_loss: 0.5337 - val_accuracy: 0.7667\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0803 - accuracy: 0.9929 - val_loss: 0.5219 - val_accuracy: 0.8000\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.0790 - accuracy: 0.9929 - val_loss: 0.5231 - val_accuracy: 0.8000\n",
            "No. of Parameters:  10333505\n",
            "Time:  423.84566473960876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:31:47.340465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.5231 - accuracy: 0.8000\n",
            "Test : > 80.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:31:50.626338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 4s 964ms/step - loss: 0.0729 - accuracy: 0.9929\n",
            "Train : > 99.286\n",
            "2/2 [==============================] - 0s 181ms/step\n"
          ]
        }
      ],
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import expand_dims as tf_expand_dims\n",
        "from tensorflow import summary\n",
        "from keras import backend as K\n",
        "from keras import callbacks\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time\n",
        "import os\n",
        "import io\n",
        "from datetime import datetime\n",
        "\n",
        "logs_folder = \"logs_vgg3\"\n",
        "if os.path.exists(logs_folder):\n",
        "    os.system(f\"rm -rf {logs_folder}\")\n",
        "\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "    # Save the plot to a PNG in memory.\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    # Convert PNG buffer to TF image\n",
        "    image = tf_image.decode_png(buf.getvalue(), channels=4)\n",
        "    # Add the batch dimension\n",
        "    image = tf_expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(images, label_arr, pred_arr):\n",
        "    \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "    # Create a figure to contain the plot.\n",
        "    figure = plt.figure(figsize=(50, 50))\n",
        "    for i in range(30):\n",
        "        # Start next subplot.\n",
        "        plt.subplot(\n",
        "            8, 5, i + 1, title=f'Actual :+{label_arr[i]}+| Pred : {pred_arr[i]}')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "    return figure\n",
        "\n",
        "# define cnn model\n",
        "\n",
        "\n",
        "def vgg_three():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "\n",
        "\n",
        "def run_test_harness():\n",
        "\n",
        "    logdir = \"logs_vgg3/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
        "    model = vgg_three()\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "    train_it = datagen.flow_from_directory('dataset_harp_vs_violin/train/',\n",
        "                                           class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    test_it = datagen.flow_from_directory('dataset_harp_vs_violin/test/',\n",
        "                                          class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    start = time.time()\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "                                  validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=1, callbacks=[tensorboard_callback],)\n",
        "    end = time.time()\n",
        "\n",
        "    print('No. of Parameters: ', model.count_params())\n",
        "\n",
        "    print(\"Time: \", end - start)\n",
        "\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n",
        "    print('Test : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    _, acc = model.evaluate_generator(train_it, steps=len(train_it), verbose=1)\n",
        "    print('Train : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    summarize_diagnostics(history)\n",
        "\n",
        "    label_dict = {}\n",
        "    for key, value in test_it.class_indices.items():\n",
        "        label_dict[value] = key\n",
        "\n",
        "    x, y = test_it.next()\n",
        "    images = x\n",
        "    labels = y\n",
        "    predictions = model.predict(images)\n",
        "    # print(x.shape,y.shape)\n",
        "    label_vals = []\n",
        "    pred_vals = []\n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        pred = round(predictions[j][0])\n",
        "        # print(k, label_dict[int(label)], label_dict[pred])\n",
        "        label_vals.append(label_dict[int(label)])\n",
        "        pred_vals.append(label_dict[pred])\n",
        "        # k += 1\n",
        "\n",
        "    figure = image_grid(images, label_vals, pred_vals)\n",
        "    file_writer = summary.create_file_writer(logdir)\n",
        "    with file_writer.as_default():\n",
        "        summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sg7YQveVVTB"
      },
      "source": [
        "# VGG 3 data aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VUHVo-HLUf_q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 140 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:32:04.530664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - ETA: 0s - loss: 0.9782 - accuracy: 0.5143"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:32:14.020590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 11s 3s/step - loss: 0.9782 - accuracy: 0.5143 - val_loss: 0.7803 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.7471 - accuracy: 0.5000 - val_loss: 0.6988 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.7068 - accuracy: 0.4857 - val_loss: 0.6971 - val_accuracy: 0.4833\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.6817 - accuracy: 0.5143 - val_loss: 0.6841 - val_accuracy: 0.4833\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6880 - accuracy: 0.5071 - val_loss: 0.6709 - val_accuracy: 0.7000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6795 - accuracy: 0.5643 - val_loss: 0.6946 - val_accuracy: 0.4833\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6807 - accuracy: 0.5857 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.6466 - accuracy: 0.6214 - val_loss: 0.6463 - val_accuracy: 0.7167\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.6276 - accuracy: 0.7000 - val_loss: 0.6329 - val_accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.6132 - accuracy: 0.7286 - val_loss: 0.6217 - val_accuracy: 0.7833\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.6035 - accuracy: 0.7000 - val_loss: 0.6119 - val_accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.5731 - accuracy: 0.7857 - val_loss: 0.6030 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.5656 - accuracy: 0.7929 - val_loss: 0.6427 - val_accuracy: 0.6167\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.5871 - accuracy: 0.6786 - val_loss: 0.6320 - val_accuracy: 0.6333\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.5342 - accuracy: 0.7500 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.5492 - accuracy: 0.6857 - val_loss: 0.5836 - val_accuracy: 0.7333\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.5145 - accuracy: 0.7857 - val_loss: 0.5848 - val_accuracy: 0.7333\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.4890 - accuracy: 0.8286 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 8s 4s/step - loss: 0.5538 - accuracy: 0.7214 - val_loss: 0.5943 - val_accuracy: 0.7167\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.4913 - accuracy: 0.7500 - val_loss: 0.6618 - val_accuracy: 0.6333\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.5432 - accuracy: 0.7214 - val_loss: 0.6162 - val_accuracy: 0.6833\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4766 - accuracy: 0.7786 - val_loss: 0.5670 - val_accuracy: 0.7333\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.4590 - accuracy: 0.7571 - val_loss: 0.5757 - val_accuracy: 0.7000\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.4773 - accuracy: 0.7857 - val_loss: 0.5518 - val_accuracy: 0.8000\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.4422 - accuracy: 0.8000 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4632 - accuracy: 0.7786 - val_loss: 0.5829 - val_accuracy: 0.7333\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.4336 - accuracy: 0.8429 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3950 - accuracy: 0.8357 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.4368 - accuracy: 0.8071 - val_loss: 0.5661 - val_accuracy: 0.7333\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3940 - accuracy: 0.8571 - val_loss: 0.6118 - val_accuracy: 0.7000\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4153 - accuracy: 0.8214 - val_loss: 0.5453 - val_accuracy: 0.7833\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3610 - accuracy: 0.8357 - val_loss: 0.5621 - val_accuracy: 0.7833\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3470 - accuracy: 0.8571 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3597 - accuracy: 0.8357 - val_loss: 0.5670 - val_accuracy: 0.7833\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3940 - accuracy: 0.7929 - val_loss: 0.5406 - val_accuracy: 0.7833\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3655 - accuracy: 0.8286 - val_loss: 0.5695 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3628 - accuracy: 0.8214 - val_loss: 0.5345 - val_accuracy: 0.7833\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3598 - accuracy: 0.8571 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.3660 - accuracy: 0.8286 - val_loss: 0.5321 - val_accuracy: 0.8167\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4182 - accuracy: 0.8143 - val_loss: 0.5232 - val_accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 9s 2s/step - loss: 0.3323 - accuracy: 0.8786 - val_loss: 0.5214 - val_accuracy: 0.8167\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3180 - accuracy: 0.8643 - val_loss: 0.5396 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3944 - accuracy: 0.8286 - val_loss: 0.5131 - val_accuracy: 0.7833\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.3460 - accuracy: 0.8786 - val_loss: 0.5185 - val_accuracy: 0.8167\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3418 - accuracy: 0.8357 - val_loss: 0.5905 - val_accuracy: 0.7667\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.3191 - accuracy: 0.8571 - val_loss: 0.5201 - val_accuracy: 0.7833\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.3987 - accuracy: 0.8143 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.2922 - accuracy: 0.8857 - val_loss: 0.7941 - val_accuracy: 0.6500\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.4780 - accuracy: 0.7286 - val_loss: 0.8161 - val_accuracy: 0.7000\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.4411 - accuracy: 0.7643 - val_loss: 0.5164 - val_accuracy: 0.7833\n",
            "No. of Parameters:  10333505\n",
            "Time:  453.12786293029785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:39:37.081629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.5164 - accuracy: 0.7833\n",
            "Test : > 78.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:39:39.972335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 5s 1s/step - loss: 0.3138 - accuracy: 0.8500\n",
            "Train : > 85.000\n",
            "2/2 [==============================] - 0s 152ms/step\n"
          ]
        }
      ],
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import expand_dims as tf_expand_dims\n",
        "from tensorflow import summary\n",
        "from keras import backend as K\n",
        "from keras import callbacks\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time\n",
        "import os\n",
        "import io\n",
        "from datetime import datetime\n",
        "\n",
        "logs_folder = \"logs_vgg3_aug\"\n",
        "if os.path.exists(logs_folder):\n",
        "    os.system(f\"rm -rf {logs_folder}\")\n",
        "\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "    # Save the plot to a PNG in memory.\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    # Convert PNG buffer to TF image\n",
        "    image = tf_image.decode_png(buf.getvalue(), channels=4)\n",
        "    # Add the batch dimension\n",
        "    image = tf_expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(images, label_arr, pred_arr):\n",
        "    \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "    # Create a figure to contain the plot.\n",
        "    figure = plt.figure(figsize=(50, 50))\n",
        "    for i in range(30):\n",
        "        # Start next subplot.\n",
        "        plt.subplot(\n",
        "            8, 5, i + 1, title=f'Actual :+{label_arr[i]}+| Pred : {pred_arr[i]}')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "    return figure\n",
        "\n",
        "# define cnn model\n",
        "\n",
        "\n",
        "def vgg_three_aug():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu',\n",
        "              kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "\n",
        "\n",
        "def run_test_harness():\n",
        "    logdir = \"logs_vgg3_aug/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
        "    model = vgg_three_aug()\n",
        "    train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                       width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "    train_it = train_datagen.flow_from_directory('dataset_harp_vs_violin/train/',\n",
        "                                                 class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    test_it = test_datagen.flow_from_directory('dataset_harp_vs_violin/test/',\n",
        "                                               class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "    start = time.time()\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "                                  validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=1, callbacks=[tensorboard_callback],)\n",
        "    end = time.time()\n",
        "\n",
        "    print('No. of Parameters: ', model.count_params())\n",
        "\n",
        "    print(\"Time: \", end - start)\n",
        "\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n",
        "    print('Test : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    _, acc = model.evaluate_generator(train_it, steps=len(train_it), verbose=1)\n",
        "    print('Train : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    summarize_diagnostics(history)\n",
        "\n",
        "    label_dict = {}\n",
        "    for key, value in test_it.class_indices.items():\n",
        "        label_dict[value] = key\n",
        "\n",
        "    x, y = test_it.next()\n",
        "    images = x\n",
        "    labels = y\n",
        "    predictions = model.predict(images)\n",
        "    # print(x.shape,y.shape)\n",
        "    label_vals = []\n",
        "    pred_vals = []\n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        pred = round(predictions[j][0])\n",
        "        # print(k, label_dict[int(label)], label_dict[pred])\n",
        "        label_vals.append(label_dict[int(label)])\n",
        "        pred_vals.append(label_dict[pred])\n",
        "        # k += 1\n",
        "\n",
        "    figure = image_grid(images, label_vals, pred_vals)\n",
        "    file_writer = summary.create_file_writer(logdir)\n",
        "    with file_writer.as_default():\n",
        "        summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSVoChmiXWwp"
      },
      "source": [
        "# VGG-16 Transfer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1LWnfND3XapL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 140 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:43:27.932975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-04-19 18:43:30.393194: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
            "2023-04-19 18:43:30.654859: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/3 [=========>....................] - ETA: 14s - loss: 5.3098 - accuracy: 0.5625"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:43:35.698610: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
            "2023-04-19 18:43:35.961106: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - ETA: 0s - loss: 8.1770 - accuracy: 0.5929"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:43:41.936947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-04-19 18:43:43.189497: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 770703360 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 19s 6s/step - loss: 8.1770 - accuracy: 0.5929 - val_loss: 4.4315 - val_accuracy: 0.8167\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 2.0059 - accuracy: 0.9071 - val_loss: 2.8875 - val_accuracy: 0.8833\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 21s 7s/step - loss: 6.2754e-04 - accuracy: 1.0000 - val_loss: 1.6343 - val_accuracy: 0.9500\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 16s 5s/step - loss: 5.3230e-04 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.9500\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 16s 5s/step - loss: 0.0735 - accuracy: 0.9857 - val_loss: 1.7093 - val_accuracy: 0.9333\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 16s 5s/step - loss: 4.1306e-14 - accuracy: 1.0000 - val_loss: 1.8598 - val_accuracy: 0.9500\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 17s 6s/step - loss: 4.0243e-17 - accuracy: 1.0000 - val_loss: 2.0415 - val_accuracy: 0.9667\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 18s 6s/step - loss: 2.6045e-18 - accuracy: 1.0000 - val_loss: 2.2135 - val_accuracy: 0.9500\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 17s 8s/step - loss: 2.1667e-18 - accuracy: 1.0000 - val_loss: 2.4119 - val_accuracy: 0.9500\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 18s 6s/step - loss: 2.2497e-18 - accuracy: 1.0000 - val_loss: 2.5614 - val_accuracy: 0.9500\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 17s 5s/step - loss: 2.6278e-18 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.9333\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 18s 9s/step - loss: 3.2128e-18 - accuracy: 1.0000 - val_loss: 2.8541 - val_accuracy: 0.9333\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 4.0152e-18 - accuracy: 1.0000 - val_loss: 2.9672 - val_accuracy: 0.9333\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 17s 8s/step - loss: 4.3525e-18 - accuracy: 1.0000 - val_loss: 3.0517 - val_accuracy: 0.9333\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 4.4484e-18 - accuracy: 1.0000 - val_loss: 3.1132 - val_accuracy: 0.9333\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 20s 9s/step - loss: 4.8227e-18 - accuracy: 1.0000 - val_loss: 3.1581 - val_accuracy: 0.9333\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 4.8795e-18 - accuracy: 1.0000 - val_loss: 3.1908 - val_accuracy: 0.9333\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 18s 9s/step - loss: 5.0599e-18 - accuracy: 1.0000 - val_loss: 3.2147 - val_accuracy: 0.9333\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 20s 9s/step - loss: 5.1561e-18 - accuracy: 1.0000 - val_loss: 3.2321 - val_accuracy: 0.9333\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.2468e-18 - accuracy: 1.0000 - val_loss: 3.2448 - val_accuracy: 0.9333\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.2801e-18 - accuracy: 1.0000 - val_loss: 3.2540 - val_accuracy: 0.9333\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 5.3073e-18 - accuracy: 1.0000 - val_loss: 3.2608 - val_accuracy: 0.9333\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 21s 7s/step - loss: 5.3389e-18 - accuracy: 1.0000 - val_loss: 3.2657 - val_accuracy: 0.9333\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.3682e-18 - accuracy: 1.0000 - val_loss: 3.2693 - val_accuracy: 0.9333\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.3876e-18 - accuracy: 1.0000 - val_loss: 3.2719 - val_accuracy: 0.9333\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 5.3947e-18 - accuracy: 1.0000 - val_loss: 3.2738 - val_accuracy: 0.9333\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.4050e-18 - accuracy: 1.0000 - val_loss: 3.2752 - val_accuracy: 0.9333\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4104e-18 - accuracy: 1.0000 - val_loss: 3.2762 - val_accuracy: 0.9333\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 5.4118e-18 - accuracy: 1.0000 - val_loss: 3.2769 - val_accuracy: 0.9333\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 5.4171e-18 - accuracy: 1.0000 - val_loss: 3.2775 - val_accuracy: 0.9333\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4179e-18 - accuracy: 1.0000 - val_loss: 3.2779 - val_accuracy: 0.9333\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.4203e-18 - accuracy: 1.0000 - val_loss: 3.2782 - val_accuracy: 0.9333\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 5.4218e-18 - accuracy: 1.0000 - val_loss: 3.2784 - val_accuracy: 0.9333\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4226e-18 - accuracy: 1.0000 - val_loss: 3.2785 - val_accuracy: 0.9333\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 20s 6s/step - loss: 5.4232e-18 - accuracy: 1.0000 - val_loss: 3.2786 - val_accuracy: 0.9333\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4237e-18 - accuracy: 1.0000 - val_loss: 3.2787 - val_accuracy: 0.9333\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 5.4238e-18 - accuracy: 1.0000 - val_loss: 3.2788 - val_accuracy: 0.9333\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.4242e-18 - accuracy: 1.0000 - val_loss: 3.2788 - val_accuracy: 0.9333\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4244e-18 - accuracy: 1.0000 - val_loss: 3.2788 - val_accuracy: 0.9333\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.4245e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4246e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 20s 7s/step - loss: 5.4246e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 19s 9s/step - loss: 5.4247e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 20s 9s/step - loss: 5.4248e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 18s 8s/step - loss: 5.4248e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 17s 8s/step - loss: 5.4249e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 17s 6s/step - loss: 5.4249e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 18s 8s/step - loss: 5.4249e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 18s 8s/step - loss: 5.4249e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 17s 8s/step - loss: 5.4249e-18 - accuracy: 1.0000 - val_loss: 3.2789 - val_accuracy: 0.9333\n",
            "No. of Parameters:  17926209\n",
            "Time:  941.8781809806824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:59:09.160696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test : > 93.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:59:15.568304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train : > 100.000\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4433c71630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 5s 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ],
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import expand_dims as tf_expand_dims\n",
        "from tensorflow import summary\n",
        "from keras import backend as K\n",
        "from keras import callbacks\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time\n",
        "import os\n",
        "import io\n",
        "from datetime import datetime\n",
        "\n",
        "logs_folder = \"logs_vgg16\"\n",
        "if os.path.exists(logs_folder):\n",
        "    os.system(f\"rm -rf {logs_folder}\")\n",
        "\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "    # Save the plot to a PNG in memory.\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    # Convert PNG buffer to TF image\n",
        "    image = tf_image.decode_png(buf.getvalue(), channels=4)\n",
        "    # Add the batch dimension\n",
        "    image = tf_expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(images, label_arr, pred_arr):\n",
        "    \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "    # Create a figure to contain the plot.\n",
        "    figure = plt.figure(figsize=(50, 50))\n",
        "    for i in range(30):\n",
        "        # Start next subplot.\n",
        "        plt.subplot(\n",
        "            8, 5, i + 1, title=f'Actual :+{label_arr[i]}+| Pred : {pred_arr[i]}')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "    return figure\n",
        "\n",
        "# define cnn model\n",
        "\n",
        "\n",
        "def define_model():\n",
        "    # load model\n",
        "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "    # mark loaded layers as not trainable\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(128, activation='relu',\n",
        "                   kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(1, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()\n",
        "\n",
        "\n",
        "def run_test_harness():\n",
        "\n",
        "    logdir = \"logs_vgg16/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
        "    model = define_model()\n",
        "    datagen = ImageDataGenerator(featurewise_center=True)\n",
        "    datagen.mean = [123.68, 116.779, 103.939]\n",
        "    train_it = datagen.flow_from_directory('dataset_harp_vs_violin/train/',\n",
        "                                           class_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "\n",
        "    test_it = datagen.flow_from_directory('dataset_harp_vs_violin/test/',\n",
        "                                          class_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "                                  validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=1, callbacks=[tensorboard_callback],)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    print('No. of Parameters: ', model.count_params())\n",
        "\n",
        "    print(\"Time: \", end - start)\n",
        "\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "    print('Test : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    _, acc = model.evaluate_generator(train_it, steps=len(train_it), verbose=0)\n",
        "    print('Train : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    summarize_diagnostics(history)\n",
        "\n",
        "    label_dict = {}\n",
        "    for key, value in test_it.class_indices.items():\n",
        "        label_dict[value] = key\n",
        "\n",
        "    x, y = test_it.next()\n",
        "    images = x\n",
        "    labels = y\n",
        "    predictions = model.predict(images)\n",
        "    # print(x.shape,y.shape)\n",
        "    label_vals = []\n",
        "    pred_vals = []\n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        pred = round(predictions[j][0])\n",
        "        # print(k, label_dict[int(label)], label_dict[pred])\n",
        "        label_vals.append(label_dict[int(label)])\n",
        "        pred_vals.append(label_dict[pred])\n",
        "        # k += 1\n",
        "\n",
        "    figure = image_grid(images, label_vals, pred_vals)\n",
        "    file_writer = summary.create_file_writer(logdir)\n",
        "    with file_writer.as_default():\n",
        "        summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Yh6sF8YgSg"
      },
      "source": [
        "# MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "rlhERLygYiIs",
        "outputId": "a121aebe-0477-409b-e0f0-bbfbc65c36ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 150528)            0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               77070848  \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,235,203\n",
            "Trainable params: 77,235,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 140 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:59:38.623988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - ETA: 0s - loss: 2.2685 - accuracy: 0.4714"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 18:59:43.493123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 6s 2s/step - loss: 2.2685 - accuracy: 0.4714 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 4s 2s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "No. of Parameters:  77235203\n",
            "Time:  205.5922999382019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 19:03:03.972398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test : > 50.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-19 19:03:05.858540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train : > 50.000\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4433f57b50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 49ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ],
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import expand_dims as tf_expand_dims\n",
        "from tensorflow import summary\n",
        "from keras import backend as K\n",
        "from keras import callbacks\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time\n",
        "import os\n",
        "import io\n",
        "from datetime import datetime\n",
        "\n",
        "logs_folder = \"logs_mlp\"\n",
        "if os.path.exists(logs_folder):\n",
        "    os.system(f\"rm -rf {logs_folder}\")\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf_image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf_expand_dims(image, 0)\n",
        "  return image\n",
        "  \n",
        "def image_grid(images,label_arr,pred_arr):\n",
        "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "  # Create a figure to contain the plot.\n",
        "  figure = plt.figure(figsize=(50,50))\n",
        "  for i in range(30):\n",
        "    # Start next subplot.\n",
        "    plt.subplot(8, 5, i + 1, title=f'Actual :+{label_arr[i]}+| Pred : {pred_arr[i]}')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "  return figure\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "  units = [512, 256, 128, 1]\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "  for i in range(len(units)):\n",
        "        model.add(Dense(units[i], activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  # Print the summary of the model to see the total number of parameters\n",
        "  model.build()\n",
        "  model.summary()\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "\n",
        "def run_test_harness():\n",
        "\n",
        "    logdir = \"logs_mlp/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
        "    model = define_model()\n",
        "    datagen = ImageDataGenerator(featurewise_center=True)\n",
        "    datagen.mean = [123.68, 116.779, 103.939]\n",
        "    train_it = datagen.flow_from_directory('dataset_harp_vs_violin/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "    \n",
        "    test_it = datagen.flow_from_directory('dataset_harp_vs_violin/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "    \n",
        "    start = time.time()\n",
        "\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "                validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=1, callbacks=[tensorboard_callback],)\n",
        "    \n",
        "    end = time.time()\n",
        "\n",
        "    print('No. of Parameters: ', model.count_params())\n",
        "\n",
        "    print(\"Time: \", end - start)\n",
        "\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "    print('Test : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    _, acc = model.evaluate_generator(train_it, steps=len(train_it), verbose=0)\n",
        "    print('Train : > %.3f' % (acc * 100.0))\n",
        "\n",
        "    summarize_diagnostics(history)\n",
        "\n",
        "    label_dict = {}\n",
        "    for key, value in test_it.class_indices.items():\n",
        "        label_dict[value] = key\n",
        "\n",
        "    x, y = test_it.next()\n",
        "    images = x\n",
        "    labels = y\n",
        "    predictions=model.predict(images)\n",
        "    # print(x.shape,y.shape)\n",
        "    label_vals=[]\n",
        "    pred_vals=[]\n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        image = images[j]\n",
        "        label = labels[j]\n",
        "        pred=round(predictions[j][0])\n",
        "        # print(k, label_dict[int(label)], label_dict[pred])\n",
        "        label_vals.append(label_dict[int(label)])\n",
        "        pred_vals.append(label_dict[pred])\n",
        "        # k += 1\n",
        "\n",
        "    figure = image_grid(images, label_vals, pred_vals)\n",
        "    file_writer = summary.create_file_writer(logdir)\n",
        "    with file_writer.as_default():\n",
        "        summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiAuxUvqc4tD"
      },
      "source": [
        "# TABLE\n",
        "\n",
        "|             Model            \t| Training Time \t| Training Loss \t| Training Accuracy \t| Testing  Accuracy \t| Number of Model Parameter \t|\n",
        "|:----------------------------:\t|:-------------:\t|:-------------:\t|:-----------------:\t|:-----------------:\t|:-------------------------:\t|\n",
        "|         VGG(1-block)         \t|     254.64    \t|               \t|        100        \t|         75        \t|          40961153         \t|\n",
        "|         VGG(3-block)         \t|      366      \t|               \t|        100        \t|         80        \t|          10333505         \t|\n",
        "| VGG(3-block)  Data Augmented \t|      397      \t|               \t|       82.143      \t|       71.667      \t|          10333505         \t|\n",
        "|  Transfer Learning (VGG-16)  \t|     181.25    \t|               \t|        100        \t|        93.3       \t|          17926209         \t|\n",
        "|           MLP Model          \t|               \t|               \t|                   \t|                   \t|                           \t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2apB_eV0d9ek"
      },
      "source": [
        "# Q1\n",
        "\n",
        "In General as the number of parameters increases the higher the capacity of learning complex neural networks. However, this may lead to overfitting as it would give good accuracy for training samples, but perform poorly for the test samples. We may note VGG16 model with transfer learning appears to have the highest test accuracy of all the models, which may be expected. Transfer learning is a powerful technique that involves leveraging a pre-trained model on a large dataset to improve the performance on a smaller, related dataset. \n",
        "\n",
        "The VGG-3 model with data augmentation appears to have a lower test accuracy than the VGG-3 model without data augmentation, which may be unexpected. Data augmentation is a common technique used to improve the generalization performance of deep learning models, but it may not always lead to better results, depending on the specifics of the dataset and the model architecture.\n",
        "\n",
        "# Q2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUxqTbo_c7gL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
